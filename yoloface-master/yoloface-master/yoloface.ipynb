{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["*******************************************************************<br>\n", "<br>\n", "Author : Thanh Nguyen, 2018<br>\n", "Email  : sthanhng@gmail.com<br>\n", "Github : https://github.com/sthanhng<br>\n", "<br>\n", "BAP, AI Team<br>\n", "Face detection using the YOLOv3 algorithm<br>\n", "<br>\n", "Description : yoloface.py<br>\n", "The main code of the Face detection using the YOLOv3 algorithm<br>\n", "<br>\n", "*******************************************************************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Usage example:  python yoloface.py --image samples/outside_000001.jpg \\<br>\n", "                                   --output-dir outputs/<br>\n", "                python yoloface.py --video samples/subway.mp4 \\<br>\n", "                                   --output-dir outputs/<br>\n", "                python yoloface.py --src 1 --output-dir outputs/"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import sys\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = argparse.ArgumentParser()\n", "parser.add_argument('--model-cfg', type=str, default='./cfg/yolov3-face.cfg',\n", "                    help='path to config file')\n", "parser.add_argument('--model-weights', type=str,\n", "                    default='./model-weights/yolov3-wider_16000.weights',\n", "                    help='path to weights of model')\n", "parser.add_argument('--image', type=str, default='',\n", "                    help='path to image file')\n", "parser.add_argument('--video', type=str, default='',\n", "                    help='path to video file')\n", "parser.add_argument('--src', type=int, default=0,\n", "                    help='source of the camera')\n", "parser.add_argument('--output-dir', type=str, default='outputs/',\n", "                    help='path to the output directory')\n", "args = parser.parse_args()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###################################################################<br>\n", "print the arguments"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('----- info -----')\n", "print('[i] The config file: ', args.model_cfg)\n", "print('[i] The weights of model file: ', args.model_weights)\n", "print('[i] Path to image file: ', args.image)\n", "print('[i] Path to video file: ', args.video)\n", "print('###########################################################\\n')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check outputs directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not os.path.exists(args.output_dir):\n", "    print('==> Creating the {} directory...'.format(args.output_dir))\n", "    os.makedirs(args.output_dir)\n", "else:\n", "    print('==> Skipping create the {} directory...'.format(args.output_dir))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Give the configuration and weight files for the model and load the network<br>\n", "using them."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net = cv2.dnn.readNetFromDarknet(args.model_cfg, args.model_weights)\n", "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n", "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _main():\n", "    wind_name = 'face detection using YOLOv3'\n", "    cv2.namedWindow(wind_name, cv2.WINDOW_NORMAL)\n", "    output_file = ''\n", "    if args.image:\n", "        if not os.path.isfile(args.image):\n", "            print(\"[!] ==> Input image file {} doesn't exist\".format(args.image))\n", "            sys.exit(1)\n", "        cap = cv2.VideoCapture(args.image)\n", "        output_file = args.image[:-4].rsplit('/')[-1] + '_yoloface.jpg'\n", "    elif args.video:\n", "        if not os.path.isfile(args.video):\n", "            print(\"[!] ==> Input video file {} doesn't exist\".format(args.video))\n", "            sys.exit(1)\n", "        cap = cv2.VideoCapture(args.video)\n", "        output_file = args.video[:-4].rsplit('/')[-1] + '_yoloface.avi'\n", "    else:\n", "        # Get data from the camera\n", "        cap = cv2.VideoCapture(args.src)\n\n", "    # Get the video writer initialized to save the output video\n", "    if not args.image:\n", "        video_writer = cv2.VideoWriter(os.path.join(args.output_dir, output_file),\n", "                                       cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n", "                                       cap.get(cv2.CAP_PROP_FPS), (\n", "                                           round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n", "                                           round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n", "    while True:\n", "        has_frame, frame = cap.read()\n\n", "        # Stop the program if reached end of video\n", "        if not has_frame:\n", "            print('[i] ==> Done processing!!!')\n", "            print('[i] ==> Output file is stored at', os.path.join(args.output_dir, output_file))\n", "            cv2.waitKey(1000)\n", "            break\n\n", "        # Create a 4D blob from a frame.\n", "        blob = cv2.dnn.blobFromImage(frame, 1 / 255, (IMG_WIDTH, IMG_HEIGHT),\n", "                                     [0, 0, 0], 1, crop=False)\n\n", "        # Sets the input to the network\n", "        net.setInput(blob)\n\n", "        # Runs the forward pass to get output of the output layers\n", "        outs = net.forward(get_outputs_names(net))\n\n", "        # Remove the bounding boxes with low confidence\n", "        faces = post_process(frame, outs, CONF_THRESHOLD, NMS_THRESHOLD)\n", "        print('[i] ==> # detected faces: {}'.format(len(faces)))\n", "        print('#' * 60)\n\n", "        # initialize the set of information we'll displaying on the frame\n", "        info = [\n", "            ('number of faces detected', '{}'.format(len(faces)))\n", "        ]\n", "        for (i, (txt, val)) in enumerate(info):\n", "            text = '{}: {}'.format(txt, val)\n", "            cv2.putText(frame, text, (10, (i * 20) + 20),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_RED, 2)\n\n", "        # Save the output video to file\n", "        if args.image:\n", "            cv2.imwrite(os.path.join(args.output_dir, output_file), frame.astype(np.uint8))\n", "        else:\n", "            video_writer.write(frame.astype(np.uint8))\n", "        cv2.imshow(wind_name, frame)\n", "        key = cv2.waitKey(1)\n", "        if key == 27 or key == ord('q'):\n", "            print('[i] ==> Interrupted by user!')\n", "            break\n", "    cap.release()\n", "    cv2.destroyAllWindows()\n", "    print('==> All done!')\n", "    print('***********************************************************')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    _main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}